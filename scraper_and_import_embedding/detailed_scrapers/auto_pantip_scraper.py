"""
Auto Pantip Scraper - ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Pantip ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Database ‡πÅ‡∏•‡∏∞ JSON file
"""
import os
import sys
import django
import json
import requests
from datetime import datetime
from bs4 import BeautifulSoup
import time

# Setup Django
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'the_one.settings')
django.setup()

from chatbot.models import Knowledgebase


class PantipScraper:
    """Scraper ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Pantip"""
    
    def __init__(self):
        self.base_url = "https://pantip.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'th,en-US;q=0.9,en;q=0.8',
        })
    
    def load_from_json(self, json_file='scraper/bigbike_faq_complete.json'):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å JSON ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà"""
        try:
            if not os.path.exists(json_file):
                print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {json_file}")
                return []
            
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {json_file}: {len(data)} records")
            return data
            
        except Exception as e:
            print(f"‚ùå Error loading JSON: {str(e)}")
            return []
    
    def transform_to_knowledgebase_format(self, item):
        """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
        try:
            # Extract from different formats
            if 'question' in item and 'answer' in item:
                # FAQ format
                title = item.get('question', '')
                content = item.get('answer', '')
                category = item.get('category', 'FAQ')
                url = item.get('url', f"https://pantip.com/topic/{item.get('id', 'unknown')}")
            elif 'title' in item:
                # Topic format
                title = item.get('title', '')
                content = item.get('content', item.get('description', ''))
                category = item.get('category', 'General')
                url = item.get('url', '')
            else:
                return None
            
            if not title or not content:
                return None
            
            data = {
                'title': title[:500],
                'content': content,
                'category': category,
                'url': url,
                'author': item.get('author', 'Unknown'),
                'views': item.get('views', 0),
                'replies': item.get('replies', 0),
                'likes': item.get('likes', item.get('votes', 0)),
                'tags': item.get('tags', []),
                'raw_data': item,
                'scraped_at': datetime.now().isoformat()
            }
            
            return data
            
        except Exception as e:
            print(f"‚ùå Transform error: {str(e)}")
            return None
    
    def save_to_database(self, data):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Database"""
        try:
            # Check if already exists
            if Knowledgebase.objects.filter(source_url=data['url']).exists():
                return False
            
            # Create new record
            kb = Knowledgebase.objects.create(
                title=data['title'][:500],
                content=data['content'],
                category=data.get('category', ''),
                source='pantip',
                source_url=data['url'],
                author=data.get('author', '')[:200],
                views=data.get('views', 0),
                replies=data.get('replies', 0),
                likes=data.get('likes', 0),
                tags=data.get('tags', []),
                raw_data=data,
                is_active=True,
                is_verified=False
            )
            
            return True
            
        except Exception as e:
            print(f"  ‚ùå DB Error: {str(e)[:100]}")
            return False
    
    def save_to_json(self, all_data, filename='pantip_knowledge.json'):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON"""
        try:
            filepath = os.path.join(os.path.dirname(__file__), filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(all_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: {filepath}")
            print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: {len(all_data)} records")
            return True
            
        except Exception as e:
            print(f"‚ùå JSON Error: {str(e)}")
            return False
    
    def run(self, json_source='scraper/bigbike_faq_complete.json', max_items=50, save_json=True):
        """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
        print("="*70)
        print("ü§ñ Pantip Auto Importer Started")
        print("="*70)
        
        # Step 1: Load from JSON
        items = self.load_from_json(json_source)
        
        if not items:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
            return
        
        items = items[:max_items]  # Limit
        
        # Step 2: Transform and import
        print(f"\nüì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(items)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...\n")
        
        processed_data = []
        success_count = 0
        skip_count = 0
        error_count = 0
        
        for i, item in enumerate(items, 1):
            # Show title
            title = item.get('question', item.get('title', 'Unknown'))[:60]
            print(f"[{i}/{len(items)}] {title}...", end=' ')
            
            # Transform
            data = self.transform_to_knowledgebase_format(item)
            
            if not data:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                error_count += 1
                continue
            
            # Save to database
            if self.save_to_database(data):
                print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                success_count += 1
                processed_data.append(data)
            else:
                print("‚è≠Ô∏è ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß")
                skip_count += 1
        
        # Step 3: Save to JSON
        if save_json and processed_data:
            self.save_to_json(processed_data)
        
        # Summary
        print("\n" + "="*70)
        print("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        print("="*70)
        print(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {success_count}")
        print(f"‚è≠Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ (‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß): {skip_count}")
        print(f"‚ùå ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {error_count}")
        print(f"üìä ‡∏£‡∏ß‡∏°: {len(items)}")
        print("="*70)
        
        # Show database stats
        total = Knowledgebase.objects.count()
        print(f"\nüìö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {total} records")
        
        return processed_data


if __name__ == '__main__':
    scraper = PantipScraper()
    scraper.run(
        json_source='scraper/bigbike_faq_complete.json',
        max_items=50,
        save_json=True
    )
